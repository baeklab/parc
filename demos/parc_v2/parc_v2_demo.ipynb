{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from keras.layers import *\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxilary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building block"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_unit(feat_dim, kernel_size, x_in):\n",
    "    # conv = Conv2D(feats, kernel, padding=\"same\")\n",
    "    res = keras.Sequential([\n",
    "        Conv2D(feat_dim,\n",
    "               kernel_size, padding=\"same\",\n",
    "               kernel_initializer='he_uniform',\n",
    "               bias_initializer='he_uniform'),\n",
    "        ReLU(),\n",
    "        Conv2D(feat_dim,\n",
    "               kernel_size,\n",
    "               padding=\"same\",\n",
    "               kernel_initializer='he_uniform',\n",
    "            bias_initializer='he_uniform')\n",
    "    ])\n",
    "    return ReLU()(x_in + res(x_in))\n",
    "\n",
    "def resnet_block(x_in, feat_dim, kernel_size, reps, pooling = True):\n",
    "    # Stage 2\n",
    "    conv1 = Conv2D(feat_dim,\n",
    "                   kernel_size,\n",
    "                   padding=\"same\",\n",
    "                   kernel_initializer='he_uniform',\n",
    "                   bias_initializer='he_uniform')(x_in)\n",
    "    relu1 = ReLU()(conv1)\n",
    "    conv2 = Conv2D(feat_dim,\n",
    "                   kernel_size,\n",
    "                   padding=\"same\",\n",
    "                   kernel_initializer='he_uniform',\n",
    "                   bias_initializer='he_uniform')(relu1)\n",
    "    x = ReLU()(conv2)\n",
    "    for _ in range(reps):\n",
    "        x = resnet_unit(feat_dim,kernel_size,x)\n",
    "    if pooling == True:\n",
    "        x = MaxPooling2D(2,2)(x)\n",
    "        return x\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_unit(feat_dim, kernel_size, x):\n",
    "    x = Conv2D(feat_dim, \n",
    "               kernel_size, \n",
    "               activation = LeakyReLU(0.2), \n",
    "               padding=\"same\", \n",
    "               kernel_initializer='he_uniform', \n",
    "               bias_initializer='he_uniform')(x)\n",
    "    x = Conv2D(feat_dim,\n",
    "               1,\n",
    "               activation = LeakyReLU(0.2),\n",
    "               padding=\"same\",\n",
    "               kernel_initializer='he_uniform',\n",
    "               bias_initializer='he_uniform')(x)\n",
    "    return x\n",
    "\n",
    "def conv_block_down(x, feat_dim, reps, kernel_size, mode = 'normal'):\n",
    "    if mode == 'down':\n",
    "        x = MaxPooling2D(2,2)(x)\n",
    "    for _ in range(reps):\n",
    "        x = conv_unit(feat_dim, \n",
    "                      kernel_size,\n",
    "                      x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def conv_block_up_w_concat(x, x1, feat_dim, reps, kernel_size, mode = 'normal'):\n",
    "    if mode == 'up':\n",
    "        x = UpSampling2D((2,2))(x)\n",
    "    \n",
    "    x = Concatenate()([x,x1])\n",
    "    for _ in range(reps):\n",
    "        x = conv_unit(feat_dim,\n",
    "                      kernel_size,\n",
    "                      x)\n",
    "    return x\n",
    "\n",
    "def conv_block_up_wo_concat(x, feat_dim, reps, kernel_size, mode = 'normal'):\n",
    "    if mode == 'up':\n",
    "        x = UpSampling2D((2,2))(x)\n",
    "    for _ in range(reps):\n",
    "        x = conv_unit(feat_dim,\n",
    "                      kernel_size,\n",
    "                      x)\n",
    "    return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPADE(layers.Layer):\n",
    "    def __init__(self, filters, epsilon=1e-5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.epsilon = epsilon\n",
    "        self.conv = layers.Conv2D(filters, 3, padding=\"same\", activation=\"relu\",kernel_initializer='he_uniform',\n",
    "               bias_initializer='he_uniform')\n",
    "        self.conv_gamma = layers.Conv2D(filters, 3, padding=\"same\",kernel_initializer='he_uniform',\n",
    "               bias_initializer='he_uniform')\n",
    "        self.conv_beta = layers.Conv2D(filters, 3, padding=\"same\",kernel_initializer='he_uniform',\n",
    "               bias_initializer='he_uniform')\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.resize_shape = input_shape[1:3]\n",
    "        # print(self.resize_shape)\n",
    "\n",
    "    def call(self, input_tensor, raw_mask):\n",
    "        mask = tf.image.resize(raw_mask, self.resize_shape, method=\"nearest\")\n",
    "        x = self.conv(mask)    \n",
    "\n",
    "        gamma = self.conv_gamma(x)\n",
    "        beta = self.conv_beta(x)\n",
    "        mean, var = tf.nn.moments(input_tensor, axes=(0, 1, 2), keepdims=True)\n",
    "        std = tf.sqrt(var + self.epsilon)\n",
    "\n",
    "        normalized = (input_tensor - mean) / std\n",
    "        output = gamma * normalized + beta\n",
    "\n",
    "        return output\n",
    "\n",
    "def spade_generator_unit(x, mask, feats_in, kernel, upsampling = True):\n",
    "    x = GaussianNoise(0.05)(x)\n",
    "    # SPADE & conv\n",
    "    spade1 = SPADE(feats_in)(x, mask)\n",
    "    output = Conv2D(feats_in,kernel, padding='same', activation= LeakyReLU(0.2),kernel_initializer='he_uniform',\n",
    "               bias_initializer='he_uniform')(spade1)\n",
    "    if upsampling == True:\n",
    "        output = UpSampling2D(size = (2,2))(output)\n",
    "        return output\n",
    "    else:\n",
    "        return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Instance Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaIN(layers.Layer):\n",
    "    def __init__(self, filters, epsilon=1e-5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.epsilon = epsilon\n",
    "        self.dense = layers.Dense(filters,\n",
    "                                  activation = 'relu',\n",
    "                                  kernel_initializer='he_uniform',\n",
    "                                  bias_initializer='he_uniform')\n",
    "        self.dense_gamma = layers.Dense(filters,\n",
    "                                        kernel_initializer='he_uniform',\n",
    "                                        bias_initializer='he_uniform')\n",
    "        self.dense_beta = layers.Dense(filters,\n",
    "                                       kernel_initializer='he_uniform',\n",
    "                                       bias_initializer='he_uniform')\n",
    "\n",
    "    def call(self, input_tensor, style_vector):\n",
    "        x = self.dense(style_vector)\n",
    "        gamma = self.dense_gamma(x)\n",
    "        beta = self.dense_beta(x)\n",
    "        #Normalize x[0]\n",
    "        mean, var = tf.nn.moments(input_tensor, axes=(0, 1, 2), keepdims=True)\n",
    "        std = tf.sqrt(var + self.epsilon)\n",
    "        normalized = (input_tensor - mean) / std\n",
    "        y = (x[0] - mean) / std\n",
    "\n",
    "        #Reshape gamma and beta\n",
    "        pool_shape = [-1, 1, 1, y.shape[-1]]\n",
    "        gamma = tf.reshape(gamma, pool_shape) + 1.0\n",
    "        beta = tf.reshape(beta, pool_shape)\n",
    "\n",
    "        return gamma * normalized + beta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_unet(n_out_features = 128, n_base_features = 64, n_channel = 5):\n",
    "    inputs = keras.Input(shape = (256,512,n_channel))\n",
    "\n",
    "    conv1 = conv_block_down(inputs,\n",
    "                            feat_dim = n_base_features,\n",
    "                            reps = 1,\n",
    "                            kernel_size = 3)\n",
    "    conv2 = conv_block_down(conv1,\n",
    "                            feat_dim = n_base_features*2,\n",
    "                            reps = 1,\n",
    "                            kernel_size = 3,\n",
    "                            mode = 'down')\n",
    "    conv3 = conv_block_down(conv2,\n",
    "                            feat_dim = n_base_features*4,\n",
    "                            reps = 1,\n",
    "                            kernel_size = 3,\n",
    "                            mode = 'down')\n",
    "    conv4 = conv_block_down(conv3,\n",
    "                            feat_dim = n_base_features*8,\n",
    "                            reps = 1,\n",
    "                            kernel_size = 3,\n",
    "                            mode = 'down')\n",
    "    conv5 = conv_block_down(conv4,\n",
    "                            feat_dim = n_base_features*16,\n",
    "                            reps = 1,\n",
    "                            kernel_size = 3,\n",
    "                            mode = 'down')\n",
    "    conv6 = conv_block_up_wo_concat(conv5,\n",
    "                                    feat_dim = n_base_features*8,\n",
    "                                    reps = 1,\n",
    "                                    kernel_size = 3,\n",
    "                                    mode = 'up')\n",
    "    \n",
    "    conv7 = conv_block_up_w_concat(conv6, conv3,\n",
    "                                    feat_dim = n_base_features*4,\n",
    "                                    reps = 1,\n",
    "                                    kernel_size = 3,\n",
    "                                    mode = 'up')\n",
    "    \n",
    "    conv8 = conv_block_up_wo_concat(conv7,\n",
    "                                    feat_dim = n_base_features*2,\n",
    "                                    reps = 1,\n",
    "                                    kernel_size = 3,\n",
    "                                    mode = 'up')\n",
    "    \n",
    "    conv9 = conv_block_up_w_concat(conv8, conv1,\n",
    "                                    feat_dim = n_out_features,\n",
    "                                    reps = 1,\n",
    "                                    kernel_size = 3,\n",
    "                                    mode = 'up')\n",
    "\n",
    "    feature_out = conv_block_up_wo_concat(conv9,\n",
    "                                    feat_dim = n_out_features,\n",
    "                                    reps = 1,\n",
    "                                    kernel_size = 1,\n",
    "                                    mode = 'normal')\n",
    "    unet = keras.Model(inputs, feature_out)\n",
    "    return unet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping and reconstruction CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_and_recon_cnn(n_base_features = 64, input_shape = (256,512,128), n_mask_channel = 1, output_channel = 1 ):\n",
    "    inputs = keras.Input(shape = input_shape)\n",
    "    inputs_2 = keras.Input(shape = (256,512,n_mask_channel))\n",
    "    spade1 = spade_generator_unit(inputs,\n",
    "                                  inputs_2,\n",
    "                                  128,\n",
    "                                  1,\n",
    "                                  upsampling = False)\n",
    "    conv1 = resnet_block(spade1,\n",
    "                         feat_dim = n_base_features,\n",
    "                         kernel_size = 1,\n",
    "                         reps = 2,\n",
    "                         pooling = False)\n",
    "    spade2 = spade_generator_unit(conv1,\n",
    "                                  inputs_2,\n",
    "                                  n_base_features,\n",
    "                                  1,\n",
    "                                  upsampling = False)\n",
    "    conv2 = resnet_block(spade2,\n",
    "                         feat_dim = n_base_features*2,\n",
    "                         kernel_size = 1,\n",
    "                         reps = 2,\n",
    "                         pooling = False)\n",
    "    \n",
    "    spade3 = spade_generator_unit(conv2,\n",
    "                                  inputs_2,\n",
    "                                  n_base_features*2,\n",
    "                                  1,\n",
    "                                  upsampling = False)\n",
    "    conv3 = resnet_block(spade3,\n",
    "                         feat_dim = n_base_features*4,\n",
    "                         kernel_size = 1,\n",
    "                         reps = 2,\n",
    "                         pooling = False)\n",
    "    conv_out = Conv2D(output_channel,1,padding='same')(conv3)\n",
    "    mapping_resnet = keras.Model([inputs,inputs_2], conv_out)\n",
    "    return mapping_resnet\n",
    "# mapping_and_recon_cnn().summary()\n",
    "# PARCv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advection layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Advection(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, state_variable, velocity_field):\n",
    "        dy, dx = tf.image.image_gradients(state_variable)\n",
    "        spatial_deriv = tf.concat([dy,dx],axis = -1)\n",
    "        advect = tf.reduce_sum(tf.multiply(spatial_deriv,velocity_field),axis = -1, keepdims=True)\n",
    "        return advect\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differentiator CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\cdy9xh\\Documents\\GitHub\\parc\\demos\\parc_v2\\parc_v2_demo.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     differentiator \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mModel([init_state_var, velocity_field], [state_var_dot_concat, velocity_dot])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m differentiator\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m differentiator(n_state_var\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\u001b[39m.\u001b[39msummary()\n",
      "\u001b[1;32mc:\\Users\\cdy9xh\\Documents\\GitHub\\parc\\demos\\parc_v2\\parc_v2_demo.ipynb Cell 21\u001b[0m in \u001b[0;36mdifferentiator\u001b[1;34m(n_state_var)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdifferentiator\u001b[39m(n_state_var \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     feature_extraction \u001b[39m=\u001b[39m feature_extraction_unet(n_channel\u001b[39m=\u001b[39;49mn_state_var\u001b[39m+\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         \u001b[39m# Mapping and recon CNN\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     mapping_and_recon \u001b[39m=\u001b[39m []\n",
      "\u001b[1;32mc:\\Users\\cdy9xh\\Documents\\GitHub\\parc\\demos\\parc_v2\\parc_v2_demo.ipynb Cell 21\u001b[0m in \u001b[0;36mfeature_extraction_unet\u001b[1;34m(n_out_features, n_base_features, n_channel)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeature_extraction_unet\u001b[39m(n_out_features \u001b[39m=\u001b[39m \u001b[39m128\u001b[39m, n_base_features \u001b[39m=\u001b[39m \u001b[39m64\u001b[39m, n_channel \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     inputs \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mInput(shape \u001b[39m=\u001b[39m (\u001b[39m256\u001b[39m,\u001b[39m512\u001b[39m,n_channel))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     conv1 \u001b[39m=\u001b[39m conv_block_down(inputs,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                             feat_dim \u001b[39m=\u001b[39;49m n_base_features,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                             reps \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                             kernel_size \u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     conv2 \u001b[39m=\u001b[39m conv_block_down(conv1,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                             feat_dim \u001b[39m=\u001b[39m n_base_features\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                             reps \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                             kernel_size \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                             mode \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdown\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     conv3 \u001b[39m=\u001b[39m conv_block_down(conv2,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m                             feat_dim \u001b[39m=\u001b[39m n_base_features\u001b[39m*\u001b[39m\u001b[39m4\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                             reps \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                             kernel_size \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                             mode \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdown\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\cdy9xh\\Documents\\GitHub\\parc\\demos\\parc_v2\\parc_v2_demo.ipynb Cell 21\u001b[0m in \u001b[0;36mconv_block_down\u001b[1;34m(x, feat_dim, reps, kernel_size, mode)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     x \u001b[39m=\u001b[39m MaxPooling2D(\u001b[39m2\u001b[39m,\u001b[39m2\u001b[39m)(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(reps):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     x \u001b[39m=\u001b[39m conv_unit(feat_dim, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m                   kernel_size,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m                   x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[1;32mc:\\Users\\cdy9xh\\Documents\\GitHub\\parc\\demos\\parc_v2\\parc_v2_demo.ipynb Cell 21\u001b[0m in \u001b[0;36mconv_unit\u001b[1;34m(feat_dim, kernel_size, x)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconv_unit\u001b[39m(feat_dim, kernel_size, x):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     x \u001b[39m=\u001b[39m Conv2D(feat_dim, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                kernel_size, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                activation \u001b[39m=\u001b[39;49m LeakyReLU(\u001b[39m0.2\u001b[39;49m), \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                padding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msame\u001b[39;49m\u001b[39m\"\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                kernel_initializer\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mhe_uniform\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                bias_initializer\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mhe_uniform\u001b[39;49m\u001b[39m'\u001b[39;49m)(x)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     x \u001b[39m=\u001b[39m Conv2D(feat_dim,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                \u001b[39m1\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                activation \u001b[39m=\u001b[39m LeakyReLU(\u001b[39m0.2\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                padding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msame\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                kernel_initializer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhe_uniform\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m                bias_initializer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhe_uniform\u001b[39m\u001b[39m'\u001b[39m)(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cdy9xh/Documents/GitHub/parc/demos/parc_v2/parc_v2_demo.ipynb#X26sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\keras\\engine\\base_layer.py:1032\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1026\u001b[0m \u001b[39m# Functional Model construction mode is invoked when `Layer`s are called on\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[39m# symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m \u001b[39m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m \u001b[39m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[0;32m   1030\u001b[0m \u001b[39m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[0;32m   1031\u001b[0m \u001b[39mif\u001b[39;00m _in_functional_construction_mode(\u001b[39mself\u001b[39m, inputs, args, kwargs, input_list):\n\u001b[1;32m-> 1032\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m   1033\u001b[0m                                             input_list)\n\u001b[0;32m   1035\u001b[0m \u001b[39m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m call_context \u001b[39m=\u001b[39m base_layer_utils\u001b[39m.\u001b[39mcall_context()\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\keras\\engine\\base_layer.py:1173\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1168\u001b[0m     training_arg_passed_by_framework \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m \u001b[39mwith\u001b[39;00m call_context\u001b[39m.\u001b[39menter(\n\u001b[0;32m   1171\u001b[0m     layer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, inputs\u001b[39m=\u001b[39minputs, build_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39mtraining_value):\n\u001b[0;32m   1172\u001b[0m   \u001b[39m# Check input assumptions set after layer building, e.g. input shape.\u001b[39;00m\n\u001b[1;32m-> 1173\u001b[0m   outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_keras_tensor_symbolic_call(\n\u001b[0;32m   1174\u001b[0m       inputs, input_masks, args, kwargs)\n\u001b[0;32m   1176\u001b[0m   \u001b[39mif\u001b[39;00m outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1177\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mA layer\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39ms `call` method should return a \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1178\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mTensor or a list of Tensors, not None \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1179\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39m(layer: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m).\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\keras\\engine\\base_layer.py:897\u001b[0m, in \u001b[0;36mLayer._keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    895\u001b[0m   \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mmap_structure(keras_tensor\u001b[39m.\u001b[39mKerasTensor, output_signature)\n\u001b[0;32m    896\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 897\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_infer_output_signature(inputs, args, kwargs, input_masks)\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\keras\\engine\\base_layer.py:940\u001b[0m, in \u001b[0;36mLayer._infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[39mwith\u001b[39;00m backend\u001b[39m.\u001b[39mname_scope(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name_scope()):  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    935\u001b[0m   \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m    936\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[0;32m    937\u001b[0m     \u001b[39m# Build layer if applicable (if the `build` method has been\u001b[39;00m\n\u001b[0;32m    938\u001b[0m     \u001b[39m# overridden).\u001b[39;00m\n\u001b[0;32m    939\u001b[0m     \u001b[39m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[39;00m\n\u001b[1;32m--> 940\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_build(inputs)\n\u001b[0;32m    941\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs)\n\u001b[0;32m    942\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\keras\\engine\\base_layer.py:2742\u001b[0m, in \u001b[0;36mLayer._maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2737\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild, \u001b[39m'\u001b[39m\u001b[39m_is_default\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m   2738\u001b[0m   \u001b[39m# Any setup work performed only once should happen in an `init_scope`\u001b[39;00m\n\u001b[0;32m   2739\u001b[0m   \u001b[39m# to avoid creating symbolic Tensors that will later pollute any eager\u001b[39;00m\n\u001b[0;32m   2740\u001b[0m   \u001b[39m# operations.\u001b[39;00m\n\u001b[0;32m   2741\u001b[0m   \u001b[39mwith\u001b[39;00m tf_utils\u001b[39m.\u001b[39mmaybe_init_scope(\u001b[39mself\u001b[39m):\n\u001b[1;32m-> 2742\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild(input_shapes)  \u001b[39m# pylint:disable=not-callable\u001b[39;00m\n\u001b[0;32m   2743\u001b[0m \u001b[39m# We must set also ensure that the layer is marked as built, and the build\u001b[39;00m\n\u001b[0;32m   2744\u001b[0m \u001b[39m# shape is stored since user defined build functions may not be calling\u001b[39;00m\n\u001b[0;32m   2745\u001b[0m \u001b[39m# `super.build()`\u001b[39;00m\n\u001b[0;32m   2746\u001b[0m Layer\u001b[39m.\u001b[39mbuild(\u001b[39mself\u001b[39m, input_shapes)\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\keras\\layers\\convolutional.py:201\u001b[0m, in \u001b[0;36mConv.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[39m# compute_output_shape contains some validation logic for the input shape,\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# and make sure the output shape has all positive dimensions.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_output_shape(input_shape)\n\u001b[1;32m--> 201\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_weight(\n\u001b[0;32m    202\u001b[0m     name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mkernel\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m    203\u001b[0m     shape\u001b[39m=\u001b[39;49mkernel_shape,\n\u001b[0;32m    204\u001b[0m     initializer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_initializer,\n\u001b[0;32m    205\u001b[0m     regularizer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_regularizer,\n\u001b[0;32m    206\u001b[0m     constraint\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_constraint,\n\u001b[0;32m    207\u001b[0m     trainable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    208\u001b[0m     dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype)\n\u001b[0;32m    209\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_bias:\n\u001b[0;32m    210\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_weight(\n\u001b[0;32m    211\u001b[0m       name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbias\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    212\u001b[0m       shape\u001b[39m=\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilters,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m       trainable\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    217\u001b[0m       dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\keras\\engine\\base_layer.py:678\u001b[0m, in \u001b[0;36mLayer.add_weight\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[0;32m    673\u001b[0m     tf_logging\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m    674\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m`caching_device` does not work with mixed precision API. Ignoring \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    675\u001b[0m         \u001b[39m'\u001b[39m\u001b[39muser specified `caching_device`.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    676\u001b[0m     caching_device \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m variable \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_add_variable_with_custom_getter(\n\u001b[0;32m    679\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m    680\u001b[0m     shape\u001b[39m=\u001b[39;49mshape,\n\u001b[0;32m    681\u001b[0m     \u001b[39m# TODO(allenl): a `make_variable` equivalent should be added as a\u001b[39;49;00m\n\u001b[0;32m    682\u001b[0m     \u001b[39m# `Trackable` method.\u001b[39;49;00m\n\u001b[0;32m    683\u001b[0m     getter\u001b[39m=\u001b[39;49mgetter,\n\u001b[0;32m    684\u001b[0m     \u001b[39m# Manage errors in Layer rather than Trackable.\u001b[39;49;00m\n\u001b[0;32m    685\u001b[0m     overwrite\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    686\u001b[0m     initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[0;32m    687\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    688\u001b[0m     constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[0;32m    689\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[0;32m    690\u001b[0m     use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[0;32m    691\u001b[0m     collections\u001b[39m=\u001b[39;49mcollections_arg,\n\u001b[0;32m    692\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[0;32m    693\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[0;32m    694\u001b[0m     caching_device\u001b[39m=\u001b[39;49mcaching_device)\n\u001b[0;32m    695\u001b[0m \u001b[39mif\u001b[39;00m regularizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    696\u001b[0m   \u001b[39m# TODO(fchollet): in the future, this should be handled at the\u001b[39;00m\n\u001b[0;32m    697\u001b[0m   \u001b[39m# level of variable creation, and weight regularization losses\u001b[39;00m\n\u001b[0;32m    698\u001b[0m   \u001b[39m# should be variable attributes.\u001b[39;00m\n\u001b[0;32m    699\u001b[0m   name_in_scope \u001b[39m=\u001b[39m variable\u001b[39m.\u001b[39mname[:variable\u001b[39m.\u001b[39mname\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m'\u001b[39m)]\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:915\u001b[0m, in \u001b[0;36mTrackable._add_variable_with_custom_getter\u001b[1;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[0;32m    905\u001b[0m   \u001b[39mif\u001b[39;00m (checkpoint_initializer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    906\u001b[0m       \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(initializer, CheckpointInitialValueCallable) \u001b[39mand\u001b[39;00m\n\u001b[0;32m    907\u001b[0m            (initializer\u001b[39m.\u001b[39mrestore_uid \u001b[39m>\u001b[39m checkpoint_initializer\u001b[39m.\u001b[39mrestore_uid))):\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    912\u001b[0m     \u001b[39m# then we'll catch that when we call _track_trackable. So this is\u001b[39;00m\n\u001b[0;32m    913\u001b[0m     \u001b[39m# \"best effort\" to set the initializer with the highest restore UID.\u001b[39;00m\n\u001b[0;32m    914\u001b[0m     initializer \u001b[39m=\u001b[39m checkpoint_initializer\n\u001b[1;32m--> 915\u001b[0m new_variable \u001b[39m=\u001b[39m getter(\n\u001b[0;32m    916\u001b[0m     name\u001b[39m=\u001b[39mname,\n\u001b[0;32m    917\u001b[0m     shape\u001b[39m=\u001b[39mshape,\n\u001b[0;32m    918\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m    919\u001b[0m     initializer\u001b[39m=\u001b[39minitializer,\n\u001b[0;32m    920\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs_for_getter)\n\u001b[0;32m    922\u001b[0m \u001b[39m# If we set an initializer and the variable processed it, tracking will not\u001b[39;00m\n\u001b[0;32m    923\u001b[0m \u001b[39m# assign again. It will add this variable to our dependencies, and if there\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[39m# is a non-trivial restoration queued, it will handle that. This also\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \u001b[39m# handles slot variables.\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m overwrite \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(new_variable, Trackable):\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\keras\\engine\\base_layer_utils.py:117\u001b[0m, in \u001b[0;36mmake_variable\u001b[1;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[0;32m    112\u001b[0m   use_resource \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[39m# In theory, in `use_resource` is True and `collections` is empty\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[39m# (that is to say, in TF2), we can use tf.Variable.\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[39m# However, this breaks legacy (Estimator) checkpoints\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[39m# because it changes variable names. Remove this when V1 is fully deprecated.\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mcompat\u001b[39m.\u001b[39;49mv1\u001b[39m.\u001b[39;49mVariable(\n\u001b[0;32m    118\u001b[0m     initial_value\u001b[39m=\u001b[39;49minit_val,\n\u001b[0;32m    119\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m    120\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[0;32m    121\u001b[0m     caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[0;32m    122\u001b[0m     dtype\u001b[39m=\u001b[39;49mvariable_dtype,\n\u001b[0;32m    123\u001b[0m     validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[0;32m    124\u001b[0m     constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[0;32m    125\u001b[0m     use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[0;32m    126\u001b[0m     collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[0;32m    127\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[0;32m    128\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[0;32m    129\u001b[0m     shape\u001b[39m=\u001b[39;49mvariable_shape \u001b[39mif\u001b[39;49;00m variable_shape \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:265\u001b[0m, in \u001b[0;36mVariableMetaclass.__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[39m@traceback_utils\u001b[39m\u001b[39m.\u001b[39mfilter_traceback\n\u001b[0;32m    263\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    264\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m VariableV1:\n\u001b[1;32m--> 265\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_variable_v1_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    266\u001b[0m   \u001b[39melif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m Variable:\n\u001b[0;32m    267\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_variable_v2_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:210\u001b[0m, in \u001b[0;36mVariableMetaclass._variable_v1_call\u001b[1;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[39mif\u001b[39;00m aggregation \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m   aggregation \u001b[39m=\u001b[39m VariableAggregation\u001b[39m.\u001b[39mNONE\n\u001b[1;32m--> 210\u001b[0m \u001b[39mreturn\u001b[39;00m previous_getter(\n\u001b[0;32m    211\u001b[0m     initial_value\u001b[39m=\u001b[39;49minitial_value,\n\u001b[0;32m    212\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[0;32m    213\u001b[0m     collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[0;32m    214\u001b[0m     validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[0;32m    215\u001b[0m     caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[0;32m    216\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m    217\u001b[0m     variable_def\u001b[39m=\u001b[39;49mvariable_def,\n\u001b[0;32m    218\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    219\u001b[0m     expected_shape\u001b[39m=\u001b[39;49mexpected_shape,\n\u001b[0;32m    220\u001b[0m     import_scope\u001b[39m=\u001b[39;49mimport_scope,\n\u001b[0;32m    221\u001b[0m     constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[0;32m    222\u001b[0m     use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[0;32m    223\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[0;32m    224\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[0;32m    225\u001b[0m     shape\u001b[39m=\u001b[39;49mshape)\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:203\u001b[0m, in \u001b[0;36mVariableMetaclass._variable_v1_call.<locals>.<lambda>\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_variable_v1_call\u001b[39m(\u001b[39mcls\u001b[39m,\n\u001b[0;32m    187\u001b[0m                       initial_value\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    188\u001b[0m                       trainable\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    200\u001b[0m                       aggregation\u001b[39m=\u001b[39mVariableAggregation\u001b[39m.\u001b[39mNONE,\n\u001b[0;32m    201\u001b[0m                       shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    202\u001b[0m   \u001b[39m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 203\u001b[0m   previous_getter \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: default_variable_creator(\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    204\u001b[0m   \u001b[39mfor\u001b[39;00m _, getter \u001b[39min\u001b[39;00m ops\u001b[39m.\u001b[39mget_default_graph()\u001b[39m.\u001b[39m_variable_creator_stack:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    205\u001b[0m     previous_getter \u001b[39m=\u001b[39m _make_getter(getter, previous_getter)\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py:2707\u001b[0m, in \u001b[0;36mdefault_variable_creator\u001b[1;34m(next_creator, **kwargs)\u001b[0m\n\u001b[0;32m   2705\u001b[0m \u001b[39mif\u001b[39;00m use_resource:\n\u001b[0;32m   2706\u001b[0m   distribute_strategy \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdistribute_strategy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 2707\u001b[0m   \u001b[39mreturn\u001b[39;00m resource_variable_ops\u001b[39m.\u001b[39;49mResourceVariable(\n\u001b[0;32m   2708\u001b[0m       initial_value\u001b[39m=\u001b[39;49minitial_value,\n\u001b[0;32m   2709\u001b[0m       trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[0;32m   2710\u001b[0m       collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[0;32m   2711\u001b[0m       validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[0;32m   2712\u001b[0m       caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[0;32m   2713\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m   2714\u001b[0m       dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   2715\u001b[0m       constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[0;32m   2716\u001b[0m       variable_def\u001b[39m=\u001b[39;49mvariable_def,\n\u001b[0;32m   2717\u001b[0m       import_scope\u001b[39m=\u001b[39;49mimport_scope,\n\u001b[0;32m   2718\u001b[0m       distribute_strategy\u001b[39m=\u001b[39;49mdistribute_strategy,\n\u001b[0;32m   2719\u001b[0m       synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[0;32m   2720\u001b[0m       aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[0;32m   2721\u001b[0m       shape\u001b[39m=\u001b[39;49mshape)\n\u001b[0;32m   2722\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2723\u001b[0m   \u001b[39mreturn\u001b[39;00m variables\u001b[39m.\u001b[39mRefVariable(\n\u001b[0;32m   2724\u001b[0m       initial_value\u001b[39m=\u001b[39minitial_value,\n\u001b[0;32m   2725\u001b[0m       trainable\u001b[39m=\u001b[39mtrainable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2736\u001b[0m       aggregation\u001b[39m=\u001b[39maggregation,\n\u001b[0;32m   2737\u001b[0m       shape\u001b[39m=\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:269\u001b[0m, in \u001b[0;36mVariableMetaclass.__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    267\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_variable_v2_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    268\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 269\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m(VariableMetaclass, \u001b[39mcls\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1665\u001b[0m, in \u001b[0;36mResourceVariable.__init__\u001b[1;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m   1663\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_from_proto(variable_def, import_scope\u001b[39m=\u001b[39mimport_scope)\n\u001b[0;32m   1664\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1665\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_from_args(\n\u001b[0;32m   1666\u001b[0m       initial_value\u001b[39m=\u001b[39;49minitial_value,\n\u001b[0;32m   1667\u001b[0m       trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[0;32m   1668\u001b[0m       collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[0;32m   1669\u001b[0m       caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[0;32m   1670\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m   1671\u001b[0m       dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1672\u001b[0m       constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[0;32m   1673\u001b[0m       synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[0;32m   1674\u001b[0m       aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[0;32m   1675\u001b[0m       shape\u001b[39m=\u001b[39;49mshape,\n\u001b[0;32m   1676\u001b[0m       distribute_strategy\u001b[39m=\u001b[39;49mdistribute_strategy)\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1811\u001b[0m, in \u001b[0;36mResourceVariable._init_from_args\u001b[1;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[0;32m   1809\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(\u001b[39m\"\u001b[39m\u001b[39mInitializer\u001b[39m\u001b[39m\"\u001b[39m), device_context_manager(\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1810\u001b[0m   \u001b[39mif\u001b[39;00m init_from_fn:\n\u001b[1;32m-> 1811\u001b[0m     initial_value \u001b[39m=\u001b[39m initial_value()\n\u001b[0;32m   1812\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(initial_value, trackable\u001b[39m.\u001b[39mCheckpointInitialValue):\n\u001b[0;32m   1813\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_initialize_trackable()\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:535\u001b[0m, in \u001b[0;36mVarianceScaling.__call__\u001b[1;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    534\u001b[0m   limit \u001b[39m=\u001b[39m math\u001b[39m.\u001b[39msqrt(\u001b[39m3.0\u001b[39m \u001b[39m*\u001b[39m scale)\n\u001b[1;32m--> 535\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_random_generator\u001b[39m.\u001b[39;49mrandom_uniform(shape, \u001b[39m-\u001b[39;49mlimit, limit, dtype)\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\keras\\backend.py:1920\u001b[0m, in \u001b[0;36mRandomGenerator.random_uniform\u001b[1;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[0;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generator:\n\u001b[0;32m   1918\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generator\u001b[39m.\u001b[39muniform(\n\u001b[0;32m   1919\u001b[0m       shape\u001b[39m=\u001b[39mshape, minval\u001b[39m=\u001b[39mminval, maxval\u001b[39m=\u001b[39mmaxval, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m-> 1920\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49muniform(\n\u001b[0;32m   1921\u001b[0m     shape\u001b[39m=\u001b[39;49mshape, minval\u001b[39m=\u001b[39;49mminval, maxval\u001b[39m=\u001b[39;49mmaxval, dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1922\u001b[0m     seed\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmake_legacy_seed())\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py:296\u001b[0m, in \u001b[0;36mrandom_uniform\u001b[1;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[0;32m    294\u001b[0m   maxval \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    295\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(name, \u001b[39m\"\u001b[39m\u001b[39mrandom_uniform\u001b[39m\u001b[39m\"\u001b[39m, [shape, minval, maxval]) \u001b[39mas\u001b[39;00m name:\n\u001b[1;32m--> 296\u001b[0m   shape \u001b[39m=\u001b[39m tensor_util\u001b[39m.\u001b[39;49mshape_tensor(shape)\n\u001b[0;32m    297\u001b[0m   \u001b[39m# In case of [0,1) floating results, minval and maxval is unused. We do an\u001b[39;00m\n\u001b[0;32m    298\u001b[0m   \u001b[39m# `is` comparison here since this is cheaper than isinstance or  __eq__.\u001b[39;00m\n\u001b[0;32m    299\u001b[0m   minval_is_zero \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(minval, \u001b[39mint\u001b[39m) \u001b[39mand\u001b[39;00m minval \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:1079\u001b[0m, in \u001b[0;36mshape_tensor\u001b[1;34m(shape)\u001b[0m\n\u001b[0;32m   1073\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1074\u001b[0m     \u001b[39m# If there are Dimension objects in the shape, unwrap them. This can be a\u001b[39;00m\n\u001b[0;32m   1075\u001b[0m     \u001b[39m# problem if v1 and v2 TensorShape objects get mixed up in partial\u001b[39;00m\n\u001b[0;32m   1076\u001b[0m     \u001b[39m# conversions, leading to shapes such as (1, 2, Dimension(5)), which are\u001b[39;00m\n\u001b[0;32m   1077\u001b[0m     \u001b[39m# not convertible to Tensors because of mixed content.\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     shape \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\u001b[39mmap\u001b[39m(tensor_shape\u001b[39m.\u001b[39mdimension_value, shape))\n\u001b[1;32m-> 1079\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mconvert_to_tensor(shape, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mshape\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1695\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mconvert_to_tensor did not convert to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1691\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mthe preferred dtype: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m vs \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1692\u001b[0m                       (ret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype, preferred_dtype\u001b[39m.\u001b[39mbase_dtype))\n\u001b[0;32m   1694\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1695\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[0;32m   1697\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[0;32m   1698\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:343\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    341\u001b[0m                                          as_ref\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    342\u001b[0m   _ \u001b[39m=\u001b[39m as_ref\n\u001b[1;32m--> 343\u001b[0m   \u001b[39mreturn\u001b[39;00m constant(v, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m    171\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    172\u001b[0m   \u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \n\u001b[0;32m    174\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    268\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m\"\u001b[39m\u001b[39mtf.constant\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    278\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 279\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m    281\u001b[0m g \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\n\u001b[0;32m    282\u001b[0m tensor_value \u001b[39m=\u001b[39m attr_value_pb2\u001b[39m.\u001b[39mAttrValue()\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[0;32m    303\u001b[0m   \u001b[39m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m   t \u001b[39m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[0;32m    305\u001b[0m   \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:101\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     99\u001b[0m   \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m--> 101\u001b[0m ctx\u001b[39m.\u001b[39;49mensure_initialized()\n\u001b[0;32m    102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39mEagerTensor(value, ctx\u001b[39m.\u001b[39mdevice_name, dtype)\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:556\u001b[0m, in \u001b[0;36mContext.ensure_initialized\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    554\u001b[0m opts \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_NewContextOptions()\n\u001b[0;32m    555\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 556\u001b[0m   config_str \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39mSerializeToString()\n\u001b[0;32m    557\u001b[0m   pywrap_tfe\u001b[39m.\u001b[39mTFE_ContextOptionsSetConfig(opts, config_str)\n\u001b[0;32m    558\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_device_policy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1042\u001b[0m, in \u001b[0;36mContext.config\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[39m\"\"\"Return the ConfigProto with all runtime deltas applied.\"\"\"\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m# Ensure physical devices have been discovered and config has been imported\u001b[39;00m\n\u001b[1;32m-> 1042\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize_physical_devices()\n\u001b[0;32m   1044\u001b[0m config \u001b[39m=\u001b[39m config_pb2\u001b[39m.\u001b[39mConfigProto()\n\u001b[0;32m   1045\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\cdy9xh\\Work\\01.Research\\01.PIML\\parc\\parc-venv\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1380\u001b[0m, in \u001b[0;36mContext._initialize_physical_devices\u001b[1;34m(self, reinitialize)\u001b[0m\n\u001b[0;32m   1377\u001b[0m   \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   1379\u001b[0m devs \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTF_ListPhysicalDevices()\n\u001b[1;32m-> 1380\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_physical_devices \u001b[39m=\u001b[39m [\n\u001b[0;32m   1381\u001b[0m     PhysicalDevice(name\u001b[39m=\u001b[39md\u001b[39m.\u001b[39mdecode(), device_type\u001b[39m=\u001b[39md\u001b[39m.\u001b[39mdecode()\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m1\u001b[39m])\n\u001b[0;32m   1382\u001b[0m     \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m devs\n\u001b[0;32m   1383\u001b[0m ]\n\u001b[0;32m   1384\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_physical_device_to_index \u001b[39m=\u001b[39m {\n\u001b[0;32m   1385\u001b[0m     p: i \u001b[39mfor\u001b[39;00m i, p \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_physical_devices)\n\u001b[0;32m   1386\u001b[0m }\n\u001b[0;32m   1388\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_visible_device_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_physical_devices)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def differentiator(n_state_var = 3):\n",
    "    feature_extraction = feature_extraction_unet(n_channel=n_state_var+2)\n",
    "        # Mapping and recon CNN\n",
    "    mapping_and_recon = []\n",
    "    advection = []\n",
    "    for _ in range(n_state_var):\n",
    "        mapping_and_recon.append(mapping_and_recon_cnn())\n",
    "        advection.append(Advection())\n",
    "\n",
    "    velocity_mapping_and_recon = mapping_and_recon_cnn(n_mask_channel = n_state_var, output_channel=2)\n",
    "    \n",
    "    init_state_var = keras.layers.Input(shape = (256,512,n_state_var))\n",
    "    velocity_field = keras.layers.Input(shape = (256,512,2))\n",
    "\n",
    "    concat1 = keras.layers.concatenate([init_state_var,velocity_field],axis = -1)\n",
    "    dynamic_feature = feature_extraction(concat1)\n",
    "    advec = []\n",
    "    state_var_dot = []\n",
    "    \n",
    "    for i in range(n_state_var): \n",
    "        advec.append(advection[i](init_state_var[:,:,:,i:i+1],velocity_field))\n",
    "        state_var_dot.append(mapping_and_recon[i]([dynamic_feature,advec[i]]))\n",
    "\n",
    "    advec_concat = keras.layers.concatenate(advec,axis = -1)\n",
    "    state_var_dot_concat = keras.layers.concatenate(state_var_dot,axis = -1)\n",
    "    \n",
    "    velocity_dot = velocity_mapping_and_recon([dynamic_feature,advec_concat])\n",
    "    differentiator = keras.Model([init_state_var, velocity_field], [state_var_dot_concat, velocity_dot])\n",
    "    return differentiator\n",
    "    \n",
    "differentiator(n_state_var=3).summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrator_cnn(n_base_features = 128, n_output = 1):\n",
    "    inputs = keras.Input(shape = (256,512,n_output))\n",
    "    conv1 = resnet_block(inputs,\n",
    "                         feat_dim = n_base_features,\n",
    "                         kernel_size = 1,\n",
    "                         reps = 2,\n",
    "                         pooling = False)\n",
    "    conv2 = resnet_block(conv1,\n",
    "                         feat_dim = n_base_features*2,\n",
    "                         kernel_size = 1,\n",
    "                         reps = 2,\n",
    "                         pooling = False)\n",
    "    conv3 = resnet_block(conv2,\n",
    "                         feat_dim = n_base_features*4,\n",
    "                         kernel_size = 1,\n",
    "                         reps = 2,\n",
    "                         pooling = False)\n",
    "    conv_out = Conv2D(n_output,1,padding='same')(conv3)\n",
    "    integrator_resnet = keras.Model(inputs, conv_out)\n",
    "    return integrator_resnet\n",
    "# integrator_cnn().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_16 (InputLayer)          [(None, 256, 512, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3 (Sl  (None, 256, 512, 1)  0          ['input_16[0][0]']               \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_4 (Sl  (None, 256, 512, 1)  0          ['input_16[0][0]']               \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_5 (Sl  (None, 256, 512, 1)  0          ['input_16[0][0]']               \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " model_6 (Functional)           (None, 256, 512, 1)  1890177     ['tf.__operators__.getitem_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " model_7 (Functional)           (None, 256, 512, 1)  1890177     ['tf.__operators__.getitem_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " model_8 (Functional)           (None, 256, 512, 1)  1890177     ['tf.__operators__.getitem_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " input_17 (InputLayer)          [(None, 256, 512, 2  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 256, 512, 3)  0           ['model_6[0][0]',                \n",
      "                                                                  'model_7[0][0]',                \n",
      "                                                                  'model_8[0][0]']                \n",
      "                                                                                                  \n",
      " model_9 (Functional)           (None, 256, 512, 2)  1890818     ['input_17[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,561,349\n",
      "Trainable params: 7,561,349\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def integrator(n_state_var = 3):\n",
    "    state_integrators = []\n",
    "    for _ in range(n_state_var):\n",
    "        state_integrators.append(integrator_cnn())\n",
    "\n",
    "    velocity_integrator = integrator_cnn(n_output=2)\n",
    "\n",
    "    state_var_dot = keras.layers.Input(shape = (256,512,n_state_var))\n",
    "    velocity_dot = keras.layers.Input(shape = (256,512,2))\n",
    "\n",
    "    state_var_next = []\n",
    "        \n",
    "    for i in range(n_state_var): \n",
    "        state_var_next.append(state_integrators[i](state_var_dot[:,:,:,i:i+1]))\n",
    "\n",
    "    state_var_next = keras.layers.concatenate(state_var_next, axis=-1)\n",
    "    velocity_next = velocity_integrator(velocity_dot)\n",
    "    integrator = keras.Model([state_var_dot, velocity_dot], [state_var_next, velocity_next])\n",
    "    return integrator\n",
    "integrator(n_state_var = 3).summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARCv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"par_cv2_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_130 (InputLayer)         [(None, 256, 512, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_131 (InputLayer)         [(None, 256, 512, 2  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " model_71 (Functional)          [(None, 256, 512, 3  19823173    ['input_130[0][0]',              \n",
      "                                ),                                'input_131[0][0]',              \n",
      "                                 (None, 256, 512, 2               'add_150[0][0]',                \n",
      "                                )]                                'add_151[0][0]',                \n",
      "                                                                  'add_152[0][0]',                \n",
      "                                                                  'add_153[0][0]',                \n",
      "                                                                  'add_154[0][0]',                \n",
      "                                                                  'add_155[0][0]',                \n",
      "                                                                  'add_156[0][0]',                \n",
      "                                                                  'add_157[0][0]']                \n",
      "                                                                                                  \n",
      " model_76 (Functional)          [(None, 256, 512, 3  7561349     ['model_71[0][0]',               \n",
      "                                ),                                'model_71[0][1]',               \n",
      "                                 (None, 256, 512, 2               'model_71[1][0]',               \n",
      "                                )]                                'model_71[1][1]',               \n",
      "                                                                  'model_71[2][0]',               \n",
      "                                                                  'model_71[2][1]',               \n",
      "                                                                  'model_71[3][0]',               \n",
      "                                                                  'model_71[3][1]',               \n",
      "                                                                  'model_71[4][0]',               \n",
      "                                                                  'model_71[4][1]']               \n",
      "                                                                                                  \n",
      " add_150 (Add)                  (None, 256, 512, 3)  0           ['input_130[0][0]',              \n",
      "                                                                  'model_76[0][0]']               \n",
      "                                                                                                  \n",
      " add_151 (Add)                  (None, 256, 512, 2)  0           ['input_131[0][0]',              \n",
      "                                                                  'model_76[0][1]']               \n",
      "                                                                                                  \n",
      " add_152 (Add)                  (None, 256, 512, 3)  0           ['add_150[0][0]',                \n",
      "                                                                  'model_76[1][0]']               \n",
      "                                                                                                  \n",
      " add_153 (Add)                  (None, 256, 512, 2)  0           ['add_151[0][0]',                \n",
      "                                                                  'model_76[1][1]']               \n",
      "                                                                                                  \n",
      " add_154 (Add)                  (None, 256, 512, 3)  0           ['add_152[0][0]',                \n",
      "                                                                  'model_76[2][0]']               \n",
      "                                                                                                  \n",
      " add_155 (Add)                  (None, 256, 512, 2)  0           ['add_153[0][0]',                \n",
      "                                                                  'model_76[2][1]']               \n",
      "                                                                                                  \n",
      " add_156 (Add)                  (None, 256, 512, 3)  0           ['add_154[0][0]',                \n",
      "                                                                  'model_76[3][0]']               \n",
      "                                                                                                  \n",
      " add_157 (Add)                  (None, 256, 512, 2)  0           ['add_155[0][0]',                \n",
      "                                                                  'model_76[3][1]']               \n",
      "                                                                                                  \n",
      " add_158 (Add)                  (None, 256, 512, 3)  0           ['add_156[0][0]',                \n",
      "                                                                  'model_76[4][0]']               \n",
      "                                                                                                  \n",
      " add_159 (Add)                  (None, 256, 512, 2)  0           ['add_157[0][0]',                \n",
      "                                                                  'model_76[4][1]']               \n",
      "                                                                                                  \n",
      " concatenate_63 (Concatenate)   (None, 256, 512, 15  0           ['add_150[0][0]',                \n",
      "                                )                                 'add_152[0][0]',                \n",
      "                                                                  'add_154[0][0]',                \n",
      "                                                                  'add_156[0][0]',                \n",
      "                                                                  'add_158[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_65 (Concatenate)   (None, 256, 512, 10  0           ['add_151[0][0]',                \n",
      "                                )                                 'add_153[0][0]',                \n",
      "                                                                  'add_155[0][0]',                \n",
      "                                                                  'add_157[0][0]',                \n",
      "                                                                  'add_159[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_62 (Concatenate)   (None, 256, 512, 15  0           ['model_71[0][0]',               \n",
      "                                )                                 'model_71[1][0]',               \n",
      "                                                                  'model_71[2][0]',               \n",
      "                                                                  'model_71[3][0]',               \n",
      "                                                                  'model_71[4][0]']               \n",
      "                                                                                                  \n",
      " concatenate_64 (Concatenate)   (None, 256, 512, 10  0           ['model_71[0][1]',               \n",
      "                                )                                 'model_71[1][1]',               \n",
      "                                                                  'model_71[2][1]',               \n",
      "                                                                  'model_71[3][1]',               \n",
      "                                                                  'model_71[4][1]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 27,384,522\n",
      "Trainable params: 27,384,522\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class PARCv2(keras.Model):\n",
    "    def __init__(self, n_state_var, n_time_step, **kwargs):\n",
    "        super(PARCv2, self).__init__(**kwargs)\n",
    "        self.n_state_var = n_state_var\n",
    "        self.n_time_step = n_time_step\n",
    "        self.differentiator = differentiator(n_state_var=self.n_state_var)\n",
    "        self.integrator = integrator(n_state_var=self.n_state_var)\n",
    "\n",
    "        self.init_state_var = keras.layers.Input(shape = (256,512,self.n_state_var))\n",
    "        self.velocity_field = keras.layers.Input(shape = (256,512,2))\n",
    "        self.out = self.call([self.init_state_var, self.velocity_field])\n",
    "\n",
    "        super(PARCv2, self).__init__(\n",
    "            inputs=[self.init_state_var, self.velocity_field], outputs=self.out, **kwargs\n",
    "        )\n",
    "\n",
    "        # loss define\n",
    "        self.differentitator_loss_tracker = keras.metrics.Mean(name=\"differentiator_loss\")\n",
    "        self.state_var_loss_tracker = keras.metrics.Mean(name=\"state_var_loss_tracker\")\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "\n",
    "    def build(self):\n",
    "        self._is_graph_network = True\n",
    "        self._init_graph_network(\n",
    "            inputs=[self.init_state_var, self.velocity_field], outputs=self.out\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "        self.total_loss_tracker,\n",
    "        self.differentitator_loss_tracker,\n",
    "        self.state_var_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs, training = True):\n",
    "        state_var_init = inputs[0]\n",
    "        velocity_init = inputs[1]\n",
    "\n",
    "        state_var_all = []\n",
    "        velocity_all = []\n",
    "        state_var_dot_all = []\n",
    "        velocity_dot_all = []\n",
    "        state_var_current = state_var_init\n",
    "        velocity_current = velocity_init\n",
    "        for _ in range(self.n_time_step):\n",
    "            state_var_dot, velocity_dot = self.differentiator([state_var_current, velocity_current])\n",
    "            delta_state_var, delta_velocity = self.integrator([state_var_dot, velocity_dot])  \n",
    "\n",
    "            state_var_current = keras.layers.add([state_var_current, delta_state_var])\n",
    "            velocity_current = keras.layers.add([velocity_current, delta_velocity])\n",
    "\n",
    "            state_var_dot_all.append(state_var_dot)\n",
    "            velocity_dot_all.append(velocity_dot)\n",
    "            state_var_all.append(state_var_current)\n",
    "            velocity_all.append(velocity_current)\n",
    "        \n",
    "        state_var_dot_all = keras.layers.concatenate(state_var_dot_all, axis = -1)\n",
    "        state_var_all = keras.layers.concatenate(state_var_all, axis = -1)\n",
    "        velocity_dot_all = keras.layers.concatenate(velocity_dot_all, axis = -1)\n",
    "        velocity_all = keras.layers.concatenate(velocity_all, axis = -1)\n",
    "\n",
    "        return state_var_all, velocity_all, state_var_dot_all, velocity_dot_all\n",
    "\n",
    "    def train_step(self, data):\n",
    "        state_var_init = data[0][0]\n",
    "        velocity_init = data[0][1]\n",
    "\n",
    "        state_var_gt = data[1][0]\n",
    "        velocity_gt = data[1][1]\n",
    "        state_var_dot_gt = data[1][2]\n",
    "        velocity_dot_gt = data[1][3]\n",
    "\n",
    "        state_loss = 0\n",
    "        differentiator_loss = 0\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # AE loss\n",
    "            state_var_current = state_var_init\n",
    "            velocity_current = velocity_init\n",
    "            for ts in range(self.n_time_step):\n",
    "                state_var_dot, velocity_dot = self.differentiator([state_var_current, velocity_current])\n",
    "                delta_state_var, delta_velocity = self.integrator([state_var_dot, velocity_dot])  \n",
    "\n",
    "                state_var_current = keras.layers.add([state_var_current, delta_state_var])\n",
    "                velocity_current = keras.layers.add([velocity_current, delta_velocity])\n",
    "\n",
    "                state_range = (ts*self.n_state_var, ts*self.n_state_var+self.n_state_var-1)\n",
    "                vel_range = (ts*2, ts*2+1)\n",
    "                \n",
    "                differentiator_loss += tf.keras.losses.MeanSquaredError()(state_var_dot,state_var_dot_gt[:,:,:,state_range[0]:state_range[1]]) + \\\n",
    "                                        tf.keras.losses.MeanSquaredError()(velocity_dot,velocity_dot_gt[:,:,:,vel_range[0]:vel_range[1]])\n",
    "                state_loss += tf.keras.losses.MeanSquaredError()(state_var_current,state_var_gt[:,:,:,:,state_range[0]:state_range[1]]) + \\\n",
    "                                    tf.keras.losses.MeanSquaredError()(velocity_current,velocity_gt[:,:,:,vel_range[0]:vel_range[1]])\n",
    "\n",
    "            total_loss =  differentiator_loss + state_loss\n",
    "        \n",
    "        self.differentitator_loss_tracker.update_state(differentiator_loss)\n",
    "        self.state_var_loss_tracker.update_state(state_loss) \n",
    "        self.total_loss_tracker.update_state(total_loss) \n",
    "\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "        return {\n",
    "            \"total_loss\": self.total_loss_tracker.result(),\n",
    "            \"differentiator_loss\": self.differentitator_loss_tracker.result(),\n",
    "            \"state_var_loss_tracker\": self.state_var_loss_tracker.result(),\n",
    "        }\n",
    "parc = PARCv2(n_state_var=3,n_time_step=5)\n",
    "parc.build()\n",
    "parc.compile()\n",
    "parc.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Void  2\n",
      "(1, 512, 1024, 135)\n",
      "(25, 512, 768, 6)\n",
      "Void  5\n",
      "(1, 512, 1024, 155)\n",
      "(29, 512, 768, 6)\n",
      "Void  7\n",
      "(1, 512, 1024, 160)\n",
      "(30, 512, 768, 6)\n",
      "Void  13\n",
      "(1, 512, 1024, 115)\n",
      "(21, 512, 768, 6)\n",
      "Void  14\n",
      "(1, 512, 1024, 160)\n",
      "(30, 512, 768, 6)\n",
      "Void  15\n",
      "(1, 512, 1024, 135)\n",
      "(25, 512, 768, 6)\n",
      "Void  16\n",
      "(1, 512, 1024, 160)\n",
      "(30, 512, 768, 6)\n",
      "Void  17\n",
      "(1, 512, 1024, 100)\n",
      "(18, 512, 768, 6)\n",
      "Void  18\n",
      "(1, 512, 1024, 160)\n",
      "(30, 512, 768, 6)\n",
      "Void  19\n",
      "(1, 512, 1024, 160)\n",
      "(30, 512, 768, 6)\n",
      "Void  20\n",
      "(1, 512, 1024, 160)\n",
      "(30, 512, 768, 6)\n",
      "Void  21\n",
      "(1, 512, 1024, 120)\n",
      "(22, 512, 768, 6)\n",
      "Void  22\n",
      "(1, 512, 1024, 100)\n",
      "(18, 512, 768, 6)\n",
      "Void  23\n",
      "(1, 512, 1024, 105)\n",
      "(19, 512, 768, 6)\n",
      "Void  24\n",
      "(1, 512, 1024, 85)\n",
      "(15, 512, 768, 6)\n",
      "Void  26\n",
      "(1, 512, 1024, 160)\n",
      "(30, 512, 768, 6)\n",
      "Void  27\n",
      "(1, 512, 1024, 125)\n",
      "(23, 512, 768, 6)\n",
      "Void  28\n",
      "(1, 512, 1024, 145)\n",
      "(27, 512, 768, 6)\n",
      "Void  29\n",
      "(1, 512, 1024, 160)\n",
      "(30, 512, 768, 6)\n",
      "Void  30\n",
      "(1, 512, 1024, 105)\n",
      "(19, 512, 768, 6)\n",
      "Void  31\n",
      "(1, 512, 1024, 105)\n",
      "(19, 512, 768, 6)\n",
      "Void  32\n",
      "(1, 512, 1024, 105)\n",
      "(19, 512, 768, 6)\n",
      "Void  33\n",
      "(1, 512, 1024, 120)\n",
      "(22, 512, 768, 6)\n",
      "Void  34\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  35\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  36\n",
      "(1, 512, 1024, 160)\n",
      "(30, 512, 768, 6)\n",
      "Void  37\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  38\n",
      "(1, 512, 1024, 115)\n",
      "(21, 512, 768, 6)\n",
      "Void  39\n",
      "(1, 512, 1024, 160)\n",
      "(30, 512, 768, 6)\n",
      "Void  40\n",
      "(1, 512, 1024, 90)\n",
      "(16, 512, 768, 6)\n",
      "Void  41\n",
      "(1, 512, 1024, 95)\n",
      "(17, 512, 768, 6)\n",
      "Void  42\n",
      "(1, 512, 1024, 105)\n",
      "(19, 512, 768, 6)\n",
      "Void  43\n",
      "(1, 512, 1024, 145)\n",
      "(27, 512, 768, 6)\n",
      "Void  46\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  50\n",
      "(1, 512, 1024, 160)\n",
      "(30, 512, 768, 6)\n",
      "Void  51\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  52\n",
      "(1, 512, 1024, 165)\n",
      "(31, 512, 768, 6)\n",
      "Void  53\n",
      "(1, 512, 1024, 135)\n",
      "(25, 512, 768, 6)\n",
      "Void  54\n",
      "(1, 512, 1024, 90)\n",
      "(16, 512, 768, 6)\n",
      "Void  55\n",
      "(1, 512, 1024, 125)\n",
      "(23, 512, 768, 6)\n",
      "Void  56\n",
      "(1, 512, 1024, 160)\n",
      "(30, 512, 768, 6)\n",
      "Void  57\n",
      "(1, 512, 1024, 160)\n",
      "(30, 512, 768, 6)\n",
      "Void  60\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  61\n",
      "(1, 512, 1024, 100)\n",
      "(18, 512, 768, 6)\n",
      "Void  62\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  63\n",
      "(1, 512, 1024, 160)\n",
      "(30, 512, 768, 6)\n",
      "Void  64\n",
      "(1, 512, 1024, 105)\n",
      "(19, 512, 768, 6)\n",
      "Void  65\n",
      "(1, 512, 1024, 90)\n",
      "(16, 512, 768, 6)\n",
      "Void  66\n",
      "(1, 512, 1024, 105)\n",
      "(19, 512, 768, 6)\n",
      "Void  67\n",
      "(1, 512, 1024, 160)\n",
      "(30, 512, 768, 6)\n",
      "Void  68\n",
      "(1, 512, 1024, 155)\n",
      "(29, 512, 768, 6)\n",
      "Void  69\n",
      "(1, 512, 1024, 95)\n",
      "(17, 512, 768, 6)\n",
      "Void  70\n",
      "(1, 512, 1024, 160)\n",
      "(30, 512, 768, 6)\n",
      "Void  71\n",
      "(1, 512, 1024, 135)\n",
      "(25, 512, 768, 6)\n",
      "Void  72\n",
      "(1, 512, 1024, 160)\n",
      "(30, 512, 768, 6)\n",
      "Void  73\n",
      "(1, 512, 1024, 115)\n",
      "(21, 512, 768, 6)\n",
      "Void  74\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  75\n",
      "(1, 512, 1024, 160)\n",
      "(30, 512, 768, 6)\n",
      "Void  76\n",
      "(1, 512, 1024, 335)\n",
      "(65, 512, 768, 6)\n",
      "Void  79\n",
      "(1, 512, 1024, 190)\n",
      "(36, 512, 768, 6)\n",
      "Void  81\n",
      "(1, 512, 1024, 105)\n",
      "(19, 512, 768, 6)\n",
      "Void  82\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  83\n",
      "(1, 512, 1024, 175)\n",
      "(33, 512, 768, 6)\n",
      "Void  84\n",
      "(1, 512, 1024, 185)\n",
      "(35, 512, 768, 6)\n",
      "Void  85\n",
      "(1, 512, 1024, 150)\n",
      "(28, 512, 768, 6)\n",
      "Void  86\n",
      "(1, 512, 1024, 155)\n",
      "(29, 512, 768, 6)\n",
      "Void  87\n",
      "(1, 512, 1024, 105)\n",
      "(19, 512, 768, 6)\n",
      "Void  100\n",
      "(1, 512, 1024, 95)\n",
      "(17, 512, 768, 6)\n",
      "Void  101\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  102\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  103\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  104\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  105\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  106\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  107\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  108\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  109\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  110\n",
      "(1, 512, 1024, 100)\n",
      "(18, 512, 768, 6)\n",
      "Void  111\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  112\n",
      "(1, 512, 1024, 105)\n",
      "(19, 512, 768, 6)\n",
      "Void  113\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  114\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  115\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  117\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  118\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  119\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  120\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  122\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  123\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  124\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  125\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  126\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  127\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  128\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  129\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  130\n",
      "(1, 512, 1024, 95)\n",
      "(17, 512, 768, 6)\n",
      "Void  131\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  133\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  134\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  135\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  136\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  137\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  138\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  139\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  140\n",
      "(1, 512, 1024, 80)\n",
      "(14, 512, 768, 6)\n",
      "Void  141\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  142\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  143\n",
      "(1, 512, 1024, 90)\n",
      "(16, 512, 768, 6)\n",
      "Void  146\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  147\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  151\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  152\n",
      "(1, 512, 1024, 100)\n",
      "(18, 512, 768, 6)\n",
      "Void  153\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  154\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  155\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  156\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  157\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  158\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  159\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  160\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  161\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  162\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  163\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  165\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  166\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  168\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  170\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  171\n",
      "(1, 512, 1024, 105)\n",
      "(19, 512, 768, 6)\n",
      "Void  174\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  175\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  176\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  177\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  178\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  179\n",
      "(1, 512, 1024, 100)\n",
      "(18, 512, 768, 6)\n",
      "Void  180\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  181\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  182\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  183\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  184\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  185\n",
      "(1, 512, 1024, 105)\n",
      "(19, 512, 768, 6)\n",
      "Void  186\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  187\n",
      "(1, 512, 1024, 95)\n",
      "(17, 512, 768, 6)\n",
      "Void  188\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  189\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n",
      "Void  190\n",
      "(1, 512, 1024, 110)\n",
      "(20, 512, 768, 6)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Data processing: \n",
    "# Step 1: read data\n",
    "# Step 2: chop data into sequences (1-ts length sq, 2-ts length sq, 3-ts length sq, etc.)\n",
    "\n",
    "sequence_length = 2\n",
    "n_state_var = 3\n",
    "state_seq_whole = []\n",
    "vel_seq_whole = []\n",
    "for i in range (200):\n",
    "    file_path = 'C:/Users/cdy9xh/Work/01.Research/01.PIML/parc-meta/myenv/data/data_processed/coupled_field_with_vel/void_' + str(i) +'.npy'\n",
    "    if os.path.exists(file_path):\n",
    "        raw_data_in = np.load(file_path)\n",
    "        data_shape = np.shape(raw_data_in)\n",
    "        pad_val_y = 0\n",
    "        pad_val_x = 0\n",
    "        if data_shape[0] < 512:\n",
    "            pad_val_y = abs(data_shape[0]-512)\n",
    "        if data_shape[1] < 1024:\n",
    "            pad_val_x = abs(data_shape[1]-1024)\n",
    "            # print(pad_val_x)\n",
    "        npad = ((pad_val_y, 0), (0, pad_val_x), (0, 0))\n",
    "\n",
    "        raw_data_in = np.pad(raw_data_in, pad_width=npad,mode = 'edge')    \n",
    "        raw_data_in = np.expand_dims(raw_data_in,axis = 0)\n",
    "        data_shape = np.shape(raw_data_in)\n",
    "\n",
    "        print('Void ', str(i))\n",
    "        print(data_shape)\n",
    "\n",
    "        no_of_ts = np.uint8(data_shape[-1]/(n_state_var+2))\n",
    "        state_seq_case = []\n",
    "        vel_seq_case = []\n",
    "        for j in range(no_of_ts-sequence_length):\n",
    "            state_seq = []\n",
    "            vel_seq = []\n",
    "            for k in range(sequence_length):\n",
    "                state_clip_range = ((j+k)*(n_state_var+2),(j+k)*(n_state_var+2)+n_state_var)\n",
    "                vel_clip_range = ((j+k)*(n_state_var+2)+n_state_var,(j+k)*(n_state_var+2)+n_state_var+2)\n",
    "                state_seq.append(raw_data_in[:,:,:768,state_clip_range[0]:state_clip_range[1]])\n",
    "                vel_seq.append(raw_data_in[:,:,:768,vel_clip_range[0]:vel_clip_range[1]])\n",
    "\n",
    "            state_seq_case.append(np.concatenate(state_seq, axis = -1))\n",
    "            vel_seq_case.append(np.concatenate(vel_seq,axis = -1))\n",
    "        state_seq_case = np.concatenate(state_seq_case,axis = 0)\n",
    "        vel_seq_case = np.concatenate(vel_seq_case,axis = 0)\n",
    "        print(state_seq_case.shape)\n",
    "        state_seq_whole.append(state_seq_case)\n",
    "        vel_seq_whole.append(vel_seq_case)\n",
    "\n",
    "\n",
    "state_seq_whole = np.concatenate(state_seq_whole, axis = 0)\n",
    "vel_seq_whole = np.concatenate(vel_seq_whole, axis = 0)\n",
    "\n",
    "# print(vel_seq_whole.shape)\n",
    "\n",
    "# Step 3: Save data out \n",
    "\n",
    "# Step 4: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(state_seq_whole.shape)\n",
    "print(vel_seq_whole.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "- The training is based on the idea of stacking delta_t blocks\n",
    "- PARCv2 will be trained with an incremental for one time step at a time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence length = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e42bafa6a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parc = PARCv2(n_state_var = 3, n_time_step = 1)\n",
    "parc.build()\n",
    "parc.summary()\n",
    "parc.compile()\n",
    "parc.compile(optimizer = tf.keras.optimizers.Adam(lr=0.0001, beta_1 = 0.9, beta_2 = 0.999),metrics=['mse'])\n",
    "history = parc.fit(x=[state_seq_whole[:,:,:,:3],vel_seq_whole[:,:,:,:2]], y =[state_seq_whole[:,:,:,3:],vel_seq_whole[:,:,:,2:]],\n",
    "                    batch_size=4, epochs = 300)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence length = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence length = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence length = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence length = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence length = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence length = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence length = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
