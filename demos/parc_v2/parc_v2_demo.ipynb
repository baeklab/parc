{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from keras.layers import *\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxilary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building block"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_unit(feat_dim, kernel_size, x_in):\n",
    "    # conv = Conv2D(feats, kernel, padding=\"same\")\n",
    "    res = keras.Sequential([\n",
    "        Conv2D(feat_dim,\n",
    "               kernel_size, padding=\"same\",\n",
    "               kernel_initializer='he_uniform',\n",
    "               bias_initializer='he_uniform'),\n",
    "        ReLU(),\n",
    "        Conv2D(feat_dim,\n",
    "               kernel_size,\n",
    "               padding=\"same\",\n",
    "               kernel_initializer='he_uniform',\n",
    "            bias_initializer='he_uniform')\n",
    "    ])\n",
    "    return ReLU()(x_in + res(x_in))\n",
    "\n",
    "def resnet_block(x_in, feat_dim, kernel_size, reps, pooling = True):\n",
    "    # Stage 2\n",
    "    conv1 = Conv2D(feat_dim,\n",
    "                   kernel_size,\n",
    "                   padding=\"same\",\n",
    "                   kernel_initializer='he_uniform',\n",
    "                   bias_initializer='he_uniform')(x_in)\n",
    "    relu1 = ReLU()(conv1)\n",
    "    conv2 = Conv2D(feat_dim,\n",
    "                   kernel_size,\n",
    "                   padding=\"same\",\n",
    "                   kernel_initializer='he_uniform',\n",
    "                   bias_initializer='he_uniform')(relu1)\n",
    "    x = ReLU()(conv2)\n",
    "    for _ in range(reps):\n",
    "        x = resnet_unit(feat_dim,kernel_size,x)\n",
    "    if pooling == True:\n",
    "        x = MaxPooling2D(2,2)(x)\n",
    "        return x\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_unit(feat_dim, kernel_size, x):\n",
    "    x = Conv2D(feat_dim, \n",
    "               kernel_size, \n",
    "               activation = LeakyReLU(0.2), \n",
    "               padding=\"same\", \n",
    "               kernel_initializer='he_uniform', \n",
    "               bias_initializer='he_uniform')(x)\n",
    "    x = Conv2D(feat_dim,\n",
    "               1,\n",
    "               activation = LeakyReLU(0.2),\n",
    "               padding=\"same\",\n",
    "               kernel_initializer='he_uniform',\n",
    "               bias_initializer='he_uniform')(x)\n",
    "    return x\n",
    "\n",
    "def conv_block_down(x, feat_dim, reps, kernel_size, mode = 'normal'):\n",
    "    if mode == 'down':\n",
    "        x = MaxPooling2D(2,2)(x)\n",
    "    for _ in range(reps):\n",
    "        x = conv_unit(feat_dim, \n",
    "                      kernel_size,\n",
    "                      x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def conv_block_up_w_concat(x, x1, feat_dim, reps, kernel_size, mode = 'normal'):\n",
    "    if mode == 'up':\n",
    "        x = UpSampling2D((2,2))(x)\n",
    "    \n",
    "    x = Concatenate()([x,x1])\n",
    "    for _ in range(reps):\n",
    "        x = conv_unit(feat_dim,\n",
    "                      kernel_size,\n",
    "                      x)\n",
    "    return x\n",
    "\n",
    "def conv_block_up_wo_concat(x, feat_dim, reps, kernel_size, mode = 'normal'):\n",
    "    if mode == 'up':\n",
    "        x = UpSampling2D((2,2))(x)\n",
    "    for _ in range(reps):\n",
    "        x = conv_unit(feat_dim,\n",
    "                      kernel_size,\n",
    "                      x)\n",
    "    return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPADE(layers.Layer):\n",
    "    def __init__(self, filters, epsilon=1e-5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.epsilon = epsilon\n",
    "        self.conv = layers.Conv2D(filters, 3, padding=\"same\", activation=\"relu\",kernel_initializer='he_uniform',\n",
    "               bias_initializer='he_uniform')\n",
    "        self.conv_gamma = layers.Conv2D(filters, 3, padding=\"same\",kernel_initializer='he_uniform',\n",
    "               bias_initializer='he_uniform')\n",
    "        self.conv_beta = layers.Conv2D(filters, 3, padding=\"same\",kernel_initializer='he_uniform',\n",
    "               bias_initializer='he_uniform')\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.resize_shape = input_shape[1:3]\n",
    "        # print(self.resize_shape)\n",
    "\n",
    "    def call(self, input_tensor, raw_mask):\n",
    "        mask = tf.image.resize(raw_mask, self.resize_shape, method=\"nearest\")\n",
    "        x = self.conv(mask)    \n",
    "\n",
    "        gamma = self.conv_gamma(x)\n",
    "        beta = self.conv_beta(x)\n",
    "        mean, var = tf.nn.moments(input_tensor, axes=(0, 1, 2), keepdims=True)\n",
    "        std = tf.sqrt(var + self.epsilon)\n",
    "\n",
    "        normalized = (input_tensor - mean) / std\n",
    "        output = gamma * normalized + beta\n",
    "\n",
    "        return output\n",
    "\n",
    "def spade_generator_unit(x, mask, feats_in, kernel, upsampling = True):\n",
    "    x = GaussianNoise(0.05)(x)\n",
    "    # SPADE & conv\n",
    "    spade1 = SPADE(feats_in)(x, mask)\n",
    "    output = Conv2D(feats_in,kernel, padding='same', activation= LeakyReLU(0.2),kernel_initializer='he_uniform',\n",
    "               bias_initializer='he_uniform')(spade1)\n",
    "    if upsampling == True:\n",
    "        output = UpSampling2D(size = (2,2))(output)\n",
    "        return output\n",
    "    else:\n",
    "        return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Instance Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaIN(layers.Layer):\n",
    "    def __init__(self, filters, epsilon=1e-5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.epsilon = epsilon\n",
    "        self.dense = layers.Dense(filters,\n",
    "                                  activation = 'relu',\n",
    "                                  kernel_initializer='he_uniform',\n",
    "                                  bias_initializer='he_uniform')\n",
    "        self.dense_gamma = layers.Dense(filters,\n",
    "                                        kernel_initializer='he_uniform',\n",
    "                                        bias_initializer='he_uniform')\n",
    "        self.dense_beta = layers.Dense(filters,\n",
    "                                       kernel_initializer='he_uniform',\n",
    "                                       bias_initializer='he_uniform')\n",
    "\n",
    "    def call(self, input_tensor, style_vector):\n",
    "        x = self.dense(style_vector)\n",
    "        gamma = self.dense_gamma(x)\n",
    "        beta = self.dense_beta(x)\n",
    "        #Normalize x[0]\n",
    "        mean, var = tf.nn.moments(input_tensor, axes=(0, 1, 2), keepdims=True)\n",
    "        std = tf.sqrt(var + self.epsilon)\n",
    "        normalized = (input_tensor - mean) / std\n",
    "        y = (x[0] - mean) / std\n",
    "\n",
    "        #Reshape gamma and beta\n",
    "        pool_shape = [-1, 1, 1, y.shape[-1]]\n",
    "        gamma = tf.reshape(gamma, pool_shape) + 1.0\n",
    "        beta = tf.reshape(beta, pool_shape)\n",
    "\n",
    "        return gamma * normalized + beta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_unet(n_out_features = 128, n_base_features = 64, n_channel = 5):\n",
    "    inputs = keras.Input(shape = (256,512,n_channel))\n",
    "\n",
    "    conv1 = conv_block_down(inputs,\n",
    "                            feat_dim = n_base_features,\n",
    "                            reps = 1,\n",
    "                            kernel_size = 3)\n",
    "    conv2 = conv_block_down(conv1,\n",
    "                            feat_dim = n_base_features*2,\n",
    "                            reps = 1,\n",
    "                            kernel_size = 3,\n",
    "                            mode = 'down')\n",
    "    conv3 = conv_block_down(conv2,\n",
    "                            feat_dim = n_base_features*4,\n",
    "                            reps = 1,\n",
    "                            kernel_size = 3,\n",
    "                            mode = 'down')\n",
    "    conv4 = conv_block_down(conv3,\n",
    "                            feat_dim = n_base_features*8,\n",
    "                            reps = 1,\n",
    "                            kernel_size = 3,\n",
    "                            mode = 'down')\n",
    "    conv5 = conv_block_down(conv4,\n",
    "                            feat_dim = n_base_features*16,\n",
    "                            reps = 1,\n",
    "                            kernel_size = 3,\n",
    "                            mode = 'down')\n",
    "    conv6 = conv_block_up_wo_concat(conv5,\n",
    "                                    feat_dim = n_base_features*8,\n",
    "                                    reps = 1,\n",
    "                                    kernel_size = 3,\n",
    "                                    mode = 'up')\n",
    "    \n",
    "    conv7 = conv_block_up_w_concat(conv6, conv3,\n",
    "                                    feat_dim = n_base_features*4,\n",
    "                                    reps = 1,\n",
    "                                    kernel_size = 3,\n",
    "                                    mode = 'up')\n",
    "    \n",
    "    conv8 = conv_block_up_wo_concat(conv7,\n",
    "                                    feat_dim = n_base_features*2,\n",
    "                                    reps = 1,\n",
    "                                    kernel_size = 3,\n",
    "                                    mode = 'up')\n",
    "    \n",
    "    conv9 = conv_block_up_w_concat(conv8, conv1,\n",
    "                                    feat_dim = n_out_features,\n",
    "                                    reps = 1,\n",
    "                                    kernel_size = 3,\n",
    "                                    mode = 'up')\n",
    "\n",
    "    feature_out = conv_block_up_wo_concat(conv9,\n",
    "                                    feat_dim = n_out_features,\n",
    "                                    reps = 1,\n",
    "                                    kernel_size = 1,\n",
    "                                    mode = 'normal')\n",
    "    unet = keras.Model(inputs, feature_out)\n",
    "    return unet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping and reconstruction CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_and_recon_cnn(n_base_features = 64, input_shape = (256,512,128), n_mask_channel = 1, output_channel = 1 ):\n",
    "    inputs = keras.Input(shape = input_shape)\n",
    "    inputs_2 = keras.Input(shape = (256,512,n_mask_channel))\n",
    "    spade1 = spade_generator_unit(inputs,\n",
    "                                  inputs_2,\n",
    "                                  128,\n",
    "                                  1,\n",
    "                                  upsampling = False)\n",
    "    conv1 = resnet_block(spade1,\n",
    "                         feat_dim = n_base_features,\n",
    "                         kernel_size = 1,\n",
    "                         reps = 2,\n",
    "                         pooling = False)\n",
    "    spade2 = spade_generator_unit(conv1,\n",
    "                                  inputs_2,\n",
    "                                  n_base_features,\n",
    "                                  1,\n",
    "                                  upsampling = False)\n",
    "    conv2 = resnet_block(spade2,\n",
    "                         feat_dim = n_base_features*2,\n",
    "                         kernel_size = 1,\n",
    "                         reps = 2,\n",
    "                         pooling = False)\n",
    "    \n",
    "    spade3 = spade_generator_unit(conv2,\n",
    "                                  inputs_2,\n",
    "                                  n_base_features*2,\n",
    "                                  1,\n",
    "                                  upsampling = False)\n",
    "    conv3 = resnet_block(spade3,\n",
    "                         feat_dim = n_base_features*4,\n",
    "                         kernel_size = 1,\n",
    "                         reps = 2,\n",
    "                         pooling = False)\n",
    "    conv_out = Conv2D(output_channel,1,padding='same')(conv3)\n",
    "    mapping_resnet = keras.Model([inputs,inputs_2], conv_out)\n",
    "    return mapping_resnet\n",
    "# mapping_and_recon_cnn().summary()\n",
    "# PARCv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advection layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Advection(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, state_variable, velocity_field):\n",
    "        dy, dx = tf.image.image_gradients(state_variable)\n",
    "        spatial_deriv = tf.concat([dy,dx],axis = -1)\n",
    "        advect = tf.reduce_sum(tf.multiply(spatial_deriv,velocity_field),axis = -1, keepdims=True)\n",
    "        return advect\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differentiator CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)          [(None, 256, 512, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_11 (InputLayer)          [(None, 256, 512, 2  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 256, 512, 5)  0           ['input_10[0][0]',               \n",
      "                                                                  'input_11[0][0]']               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 256, 512, 1)  0          ['input_10[0][0]']               \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None, 256, 512, 1)  0          ['input_10[0][0]']               \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2 (Sl  (None, 256, 512, 1)  0          ['input_10[0][0]']               \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " model (Functional)             (None, 256, 512, 12  15070144    ['concatenate_2[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " advection (Advection)          (None, 256, 512, 1)  0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 , 'input_11[0][0]']              \n",
      "                                                                                                  \n",
      " advection_1 (Advection)        (None, 256, 512, 1)  0           ['tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'input_11[0][0]']               \n",
      "                                                                                                  \n",
      " advection_2 (Advection)        (None, 256, 512, 1)  0           ['tf.__operators__.getitem_2[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'input_11[0][0]']               \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, 256, 512, 1)  1186753     ['model[0][0]',                  \n",
      "                                                                  'advection[0][0]']              \n",
      "                                                                                                  \n",
      " model_2 (Functional)           (None, 256, 512, 1)  1186753     ['model[0][0]',                  \n",
      "                                                                  'advection_1[0][0]']            \n",
      "                                                                                                  \n",
      " model_3 (Functional)           (None, 256, 512, 1)  1186753     ['model[0][0]',                  \n",
      "                                                                  'advection_2[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 256, 512, 3)  0           ['advection[0][0]',              \n",
      "                                                                  'advection_1[0][0]',            \n",
      "                                                                  'advection_2[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 256, 512, 3)  0           ['model_1[0][0]',                \n",
      "                                                                  'model_2[0][0]',                \n",
      "                                                                  'model_3[0][0]']                \n",
      "                                                                                                  \n",
      " model_4 (Functional)           (None, 256, 512, 2)  1192770     ['model[0][0]',                  \n",
      "                                                                  'concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 19,823,173\n",
      "Trainable params: 19,823,173\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def differentiator(n_state_var = 3):\n",
    "    feature_extraction = feature_extraction_unet(n_channel=n_state_var+2)\n",
    "        # Mapping and recon CNN\n",
    "    mapping_and_recon = []\n",
    "    advection = []\n",
    "    for _ in range(n_state_var):\n",
    "        mapping_and_recon.append(mapping_and_recon_cnn())\n",
    "        advection.append(Advection())\n",
    "\n",
    "    velocity_mapping_and_recon = mapping_and_recon_cnn(n_mask_channel = n_state_var, output_channel=2)\n",
    "    \n",
    "    init_state_var = keras.layers.Input(shape = (256,512,n_state_var))\n",
    "    velocity_field = keras.layers.Input(shape = (256,512,2))\n",
    "\n",
    "    concat1 = keras.layers.concatenate([init_state_var,velocity_field],axis = -1)\n",
    "    dynamic_feature = feature_extraction(concat1)\n",
    "    advec = []\n",
    "    state_var_dot = []\n",
    "    \n",
    "    for i in range(n_state_var): \n",
    "        advec.append(advection[i](init_state_var[:,:,:,i:i+1],velocity_field))\n",
    "        state_var_dot.append(mapping_and_recon[i]([dynamic_feature,advec[i]]))\n",
    "\n",
    "    advec_concat = keras.layers.concatenate(advec,axis = -1)\n",
    "    state_var_dot_concat = keras.layers.concatenate(state_var_dot,axis = -1)\n",
    "    \n",
    "    velocity_dot = velocity_mapping_and_recon([dynamic_feature,advec_concat])\n",
    "    differentiator = keras.Model([init_state_var, velocity_field], [state_var_dot_concat, velocity_dot])\n",
    "    return differentiator\n",
    "    \n",
    "differentiator(n_state_var=3).summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrator_cnn(n_base_features = 128, n_output = 1):\n",
    "    inputs = keras.Input(shape = (256,512,n_output))\n",
    "    conv1 = resnet_block(inputs,\n",
    "                         feat_dim = n_base_features,\n",
    "                         kernel_size = 1,\n",
    "                         reps = 2,\n",
    "                         pooling = False)\n",
    "    conv2 = resnet_block(conv1,\n",
    "                         feat_dim = n_base_features*2,\n",
    "                         kernel_size = 1,\n",
    "                         reps = 2,\n",
    "                         pooling = False)\n",
    "    conv3 = resnet_block(conv2,\n",
    "                         feat_dim = n_base_features*4,\n",
    "                         kernel_size = 1,\n",
    "                         reps = 2,\n",
    "                         pooling = False)\n",
    "    conv_out = Conv2D(n_output,1,padding='same')(conv3)\n",
    "    integrator_resnet = keras.Model(inputs, conv_out)\n",
    "    return integrator_resnet\n",
    "# integrator_cnn().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_16 (InputLayer)          [(None, 256, 512, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3 (Sl  (None, 256, 512, 1)  0          ['input_16[0][0]']               \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_4 (Sl  (None, 256, 512, 1)  0          ['input_16[0][0]']               \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_5 (Sl  (None, 256, 512, 1)  0          ['input_16[0][0]']               \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " model_6 (Functional)           (None, 256, 512, 1)  1890177     ['tf.__operators__.getitem_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " model_7 (Functional)           (None, 256, 512, 1)  1890177     ['tf.__operators__.getitem_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " model_8 (Functional)           (None, 256, 512, 1)  1890177     ['tf.__operators__.getitem_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " input_17 (InputLayer)          [(None, 256, 512, 2  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 256, 512, 3)  0           ['model_6[0][0]',                \n",
      "                                                                  'model_7[0][0]',                \n",
      "                                                                  'model_8[0][0]']                \n",
      "                                                                                                  \n",
      " model_9 (Functional)           (None, 256, 512, 2)  1890818     ['input_17[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,561,349\n",
      "Trainable params: 7,561,349\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def integrator(n_state_var = 3):\n",
    "    state_integrators = []\n",
    "    for _ in range(n_state_var):\n",
    "        state_integrators.append(integrator_cnn())\n",
    "\n",
    "    velocity_integrator = integrator_cnn(n_output=2)\n",
    "\n",
    "    state_var_dot = keras.layers.Input(shape = (256,512,n_state_var))\n",
    "    velocity_dot = keras.layers.Input(shape = (256,512,2))\n",
    "\n",
    "    state_var_next = []\n",
    "        \n",
    "    for i in range(n_state_var): \n",
    "        state_var_next.append(state_integrators[i](state_var_dot[:,:,:,i:i+1]))\n",
    "\n",
    "    state_var_next = keras.layers.concatenate(state_var_next, axis=-1)\n",
    "    velocity_next = velocity_integrator(velocity_dot)\n",
    "    integrator = keras.Model([state_var_dot, velocity_dot], [state_var_next, velocity_next])\n",
    "    return integrator\n",
    "integrator(n_state_var = 3).summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARCv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"par_cv2_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_130 (InputLayer)         [(None, 256, 512, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_131 (InputLayer)         [(None, 256, 512, 2  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " model_71 (Functional)          [(None, 256, 512, 3  19823173    ['input_130[0][0]',              \n",
      "                                ),                                'input_131[0][0]',              \n",
      "                                 (None, 256, 512, 2               'add_150[0][0]',                \n",
      "                                )]                                'add_151[0][0]',                \n",
      "                                                                  'add_152[0][0]',                \n",
      "                                                                  'add_153[0][0]',                \n",
      "                                                                  'add_154[0][0]',                \n",
      "                                                                  'add_155[0][0]',                \n",
      "                                                                  'add_156[0][0]',                \n",
      "                                                                  'add_157[0][0]']                \n",
      "                                                                                                  \n",
      " model_76 (Functional)          [(None, 256, 512, 3  7561349     ['model_71[0][0]',               \n",
      "                                ),                                'model_71[0][1]',               \n",
      "                                 (None, 256, 512, 2               'model_71[1][0]',               \n",
      "                                )]                                'model_71[1][1]',               \n",
      "                                                                  'model_71[2][0]',               \n",
      "                                                                  'model_71[2][1]',               \n",
      "                                                                  'model_71[3][0]',               \n",
      "                                                                  'model_71[3][1]',               \n",
      "                                                                  'model_71[4][0]',               \n",
      "                                                                  'model_71[4][1]']               \n",
      "                                                                                                  \n",
      " add_150 (Add)                  (None, 256, 512, 3)  0           ['input_130[0][0]',              \n",
      "                                                                  'model_76[0][0]']               \n",
      "                                                                                                  \n",
      " add_151 (Add)                  (None, 256, 512, 2)  0           ['input_131[0][0]',              \n",
      "                                                                  'model_76[0][1]']               \n",
      "                                                                                                  \n",
      " add_152 (Add)                  (None, 256, 512, 3)  0           ['add_150[0][0]',                \n",
      "                                                                  'model_76[1][0]']               \n",
      "                                                                                                  \n",
      " add_153 (Add)                  (None, 256, 512, 2)  0           ['add_151[0][0]',                \n",
      "                                                                  'model_76[1][1]']               \n",
      "                                                                                                  \n",
      " add_154 (Add)                  (None, 256, 512, 3)  0           ['add_152[0][0]',                \n",
      "                                                                  'model_76[2][0]']               \n",
      "                                                                                                  \n",
      " add_155 (Add)                  (None, 256, 512, 2)  0           ['add_153[0][0]',                \n",
      "                                                                  'model_76[2][1]']               \n",
      "                                                                                                  \n",
      " add_156 (Add)                  (None, 256, 512, 3)  0           ['add_154[0][0]',                \n",
      "                                                                  'model_76[3][0]']               \n",
      "                                                                                                  \n",
      " add_157 (Add)                  (None, 256, 512, 2)  0           ['add_155[0][0]',                \n",
      "                                                                  'model_76[3][1]']               \n",
      "                                                                                                  \n",
      " add_158 (Add)                  (None, 256, 512, 3)  0           ['add_156[0][0]',                \n",
      "                                                                  'model_76[4][0]']               \n",
      "                                                                                                  \n",
      " add_159 (Add)                  (None, 256, 512, 2)  0           ['add_157[0][0]',                \n",
      "                                                                  'model_76[4][1]']               \n",
      "                                                                                                  \n",
      " concatenate_63 (Concatenate)   (None, 256, 512, 15  0           ['add_150[0][0]',                \n",
      "                                )                                 'add_152[0][0]',                \n",
      "                                                                  'add_154[0][0]',                \n",
      "                                                                  'add_156[0][0]',                \n",
      "                                                                  'add_158[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_65 (Concatenate)   (None, 256, 512, 10  0           ['add_151[0][0]',                \n",
      "                                )                                 'add_153[0][0]',                \n",
      "                                                                  'add_155[0][0]',                \n",
      "                                                                  'add_157[0][0]',                \n",
      "                                                                  'add_159[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_62 (Concatenate)   (None, 256, 512, 15  0           ['model_71[0][0]',               \n",
      "                                )                                 'model_71[1][0]',               \n",
      "                                                                  'model_71[2][0]',               \n",
      "                                                                  'model_71[3][0]',               \n",
      "                                                                  'model_71[4][0]']               \n",
      "                                                                                                  \n",
      " concatenate_64 (Concatenate)   (None, 256, 512, 10  0           ['model_71[0][1]',               \n",
      "                                )                                 'model_71[1][1]',               \n",
      "                                                                  'model_71[2][1]',               \n",
      "                                                                  'model_71[3][1]',               \n",
      "                                                                  'model_71[4][1]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 27,384,522\n",
      "Trainable params: 27,384,522\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class PARCv2(keras.Model):\n",
    "    def __init__(self, n_state_var, n_time_step, **kwargs):\n",
    "        super(PARCv2, self).__init__(**kwargs)\n",
    "        self.n_state_var = n_state_var\n",
    "        self.n_time_step = n_time_step\n",
    "        self.differentiator = differentiator(n_state_var=self.n_state_var)\n",
    "        self.integrator = integrator(n_state_var=self.n_state_var)\n",
    "\n",
    "        self.init_state_var = keras.layers.Input(shape = (256,512,self.n_state_var))\n",
    "        self.velocity_field = keras.layers.Input(shape = (256,512,2))\n",
    "        self.out = self.call([self.init_state_var, self.velocity_field])\n",
    "\n",
    "        super(PARCv2, self).__init__(\n",
    "            inputs=[self.init_state_var, self.velocity_field], outputs=self.out, **kwargs\n",
    "        )\n",
    "\n",
    "        # loss define\n",
    "        self.differentitator_loss_tracker = keras.metrics.Mean(name=\"differentiator_loss\")\n",
    "        self.state_var_loss_tracker = keras.metrics.Mean(name=\"state_var_loss_tracker\")\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "\n",
    "    def build(self):\n",
    "        self._is_graph_network = True\n",
    "        self._init_graph_network(\n",
    "            inputs=[self.init_state_var, self.velocity_field], outputs=self.out\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "        self.total_loss_tracker,\n",
    "        self.differentitator_loss_tracker,\n",
    "        self.state_var_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs, training = True):\n",
    "        state_var_init = inputs[0]\n",
    "        velocity_init = inputs[1]\n",
    "\n",
    "        state_var_all = []\n",
    "        velocity_all = []\n",
    "        state_var_dot_all = []\n",
    "        velocity_dot_all = []\n",
    "        state_var_current = state_var_init\n",
    "        velocity_current = velocity_init\n",
    "        for _ in range(self.n_time_step):\n",
    "            state_var_dot, velocity_dot = self.differentiator([state_var_current, velocity_current])\n",
    "            delta_state_var, delta_velocity = self.integrator([state_var_dot, velocity_dot])  \n",
    "\n",
    "            state_var_current = keras.layers.add([state_var_current, delta_state_var])\n",
    "            velocity_current = keras.layers.add([velocity_current, delta_velocity])\n",
    "\n",
    "            state_var_dot_all.append(state_var_dot)\n",
    "            velocity_dot_all.append(velocity_dot)\n",
    "            state_var_all.append(state_var_current)\n",
    "            velocity_all.append(velocity_current)\n",
    "        \n",
    "        state_var_dot_all = keras.layers.concatenate(state_var_dot_all, axis = -1)\n",
    "        state_var_all = keras.layers.concatenate(state_var_all, axis = -1)\n",
    "        velocity_dot_all = keras.layers.concatenate(velocity_dot_all, axis = -1)\n",
    "        velocity_all = keras.layers.concatenate(velocity_all, axis = -1)\n",
    "\n",
    "        return state_var_all, velocity_all, state_var_dot_all, velocity_dot_all\n",
    "\n",
    "    def train_step(self, data):\n",
    "        state_var_init = data[0][0]\n",
    "        velocity_init = data[0][1]\n",
    "\n",
    "        state_var_gt = data[1][0]\n",
    "        velocity_gt = data[1][1]\n",
    "        state_var_dot_gt = data[1][2]\n",
    "        velocity_dot_gt = data[1][3]\n",
    "\n",
    "        state_loss = 0\n",
    "        differentiator_loss = 0\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # AE loss\n",
    "            state_var_current = state_var_init\n",
    "            velocity_current = velocity_init\n",
    "            for ts in range(self.n_time_step):\n",
    "                state_var_dot, velocity_dot = self.differentiator([state_var_current, velocity_current])\n",
    "                delta_state_var, delta_velocity = self.integrator([state_var_dot, velocity_dot])  \n",
    "\n",
    "                state_var_current = keras.layers.add([state_var_current, delta_state_var])\n",
    "                velocity_current = keras.layers.add([velocity_current, delta_velocity])\n",
    "\n",
    "                state_range = (ts*self.n_state_var, ts*self.n_state_var+self.n_state_var-1)\n",
    "                vel_range = (ts*2, ts*2+1)\n",
    "                \n",
    "                differentiator_loss += tf.keras.losses.MeanSquaredError()(state_var_dot,state_var_dot_gt[:,:,:,state_range[0]:state_range[1]]) + \\\n",
    "                                        tf.keras.losses.MeanSquaredError()(velocity_dot,velocity_dot_gt[:,:,:,vel_range[0]:vel_range[1]])\n",
    "                state_loss += tf.keras.losses.MeanSquaredError()(state_var_current,state_var_gt[:,:,:,:,state_range[0]:state_range[1]]) + \\\n",
    "                                    tf.keras.losses.MeanSquaredError()(velocity_current,velocity_gt[:,:,:,vel_range[0]:vel_range[1]])\n",
    "\n",
    "            total_loss =  differentiator_loss + state_loss\n",
    "        \n",
    "        self.differentitator_loss_tracker.update_state(differentiator_loss)\n",
    "        self.state_var_loss_tracker.update_state(state_loss) \n",
    "        self.total_loss_tracker.update_state(total_loss) \n",
    "\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "        return {\n",
    "            \"total_loss\": self.total_loss_tracker.result(),\n",
    "            \"differentiator_loss\": self.differentitator_loss_tracker.result(),\n",
    "            \"state_var_loss_tracker\": self.state_var_loss_tracker.result(),\n",
    "        }\n",
    "parc = PARCv2(n_state_var=3,n_time_step=5)\n",
    "parc.build()\n",
    "parc.compile()\n",
    "parc.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Data processing: \n",
    "# Step 1: read data\n",
    "# Step 2: chop data into sequences (1-ts length sq, 2-ts length sq, 3-ts length sq, etc.)\n",
    "\n",
    "sequence_length = 5\n",
    "n_state_var = 3\n",
    "state_seq_whole = []\n",
    "vel_seq_whole = []\n",
    "for _ in range (2):\n",
    "    file_path = 'C:/Users/cdy9xh/Work/01.Research/01.PIML/parc-meta/myenv/data/data_processed/coupled_field_with_vel/void_' + str(i) +'.npy'\n",
    "    if os.path.exists(file_path):\n",
    "        raw_data_in = np.load(file_path)\n",
    "        raw_data_in = np.expand_dims(raw_data_in,axis = 0)\n",
    "        data_shape = np.shape(raw_data_in)\n",
    "        for i in range(data_shape[-1]-sequence_length):\n",
    "            state_seq_whole.append(raw_data_in[:,:,:,i*(n_state_var+2):i*(n_state_var+2)+n_state_var-1])\n",
    "            vel_seq_whole.append(raw_data_in[:,:,:,i*(n_state_var+2)+n_state_var:i*(n_state_var+2)+n_state_var+2])\n",
    "\n",
    "\n",
    "\n",
    "# Step 3: Save data out \n",
    "\n",
    "# Step 4: "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
